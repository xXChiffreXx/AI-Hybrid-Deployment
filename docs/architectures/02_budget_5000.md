# Architecture Option B: $5,000 Machine Budget

## Goal

Balance long-term local throughput with moderate upfront cost, while reducing cloud spillover for routine Track A generation workloads.

## Target Infrastructure Profile

- 1 shared research node
- 10Gb Ethernet
- 16-24 CPU cores
- 128 GB RAM target
- 4 TB NVMe SSD
- GPU or unified-memory profile suitable for larger quantized models and higher concurrency
- SSH access for small team (3-8 users)

OS remains flexible because local serving interface is standardized via `llama-server`.

## Logical Architecture

- `gateway` with route classes (`local-default`, `local-long`, `cloud-hard`)
- `llama-server` local endpoint (single high-capacity instance or two tiered instances)
- `redis` cache and queue state
- `qdrant` vector retrieval by sector
- `kb-writer` to canonical `SQLite + Parquet`
- `obsidian-projector` for generated vault indexes

## Deployment Pattern

- Single-node stack with stronger local inference capacity
- Cloud primarily reserved for hard reasoning and temporary peaks

## Memory-Constrained Operating Point

Assumptions for Track A generation profile:

- Installed memory: $M_{avail} = 128$ GB
- Safety factor: $\eta = 0.85$
- Usable memory: $\eta M_{avail} = 108.8$ GB
- Planned runtime working set (larger quantized model class, moderate concurrency): $M_{req} \approx 45 \text{ to } 80$ GB

Throughput decomposition:

- $\mu_{compute} \approx 220$ tokens/sec
- $\mu_{memory} \approx 180$ tokens/sec
- $f_{fit} = 1.00$

```math
\mu_{eff}=f_{fit}\cdot\min(\mu_{compute},\mu_{memory})=1.00\cdot 180=180
```

## Capacity Assumption

- Effective local capacity target: $\mu_{eff} = 180$ tokens/sec
- Per-source token load: $725{,}000$

Theoretical local-only source throughput:

```math
\text{sources/day} = \frac{\mu_{eff} \cdot 86400}{725000} \approx 21.46
```

## Cloud Cost Model (Instantiated)

Using the shared model in `00_cloud_cost_model.md`:

- Hard-task cloud fraction: $r_h = 0.12$
- Baseline peak demand: $44.75$ tokens/sec
- Stress peak demand: $80.56$ tokens/sec

Overflow fractions:

```math
r_{over,base}=\max\left(0,\frac{44.75-180}{44.75}\right)=0
```

```math
r_{over,stress}=\max\left(0,\frac{80.56-180}{80.56}\right)=0
```

Monthly cloud cost:

```math
C_{month}=S\left(r_hc_h+(1-r_h)r_{over}c_e\right)
```

with $c_e=0.33925$, $c_h=1.69625$.

Baseline (`S=40`):

```math
C_{base}=40\left(0.12\cdot1.69625+0.88\cdot0\cdot0.33925\right)=\$8.14/month
```

Stress (`S=72`):

```math
C_{stress}=72\left(0.12\cdot1.69625+0.88\cdot0\cdot0.33925\right)=\$14.66/month
```

Approximate annual cloud range from this model: `$98 - $176`.

## Test Deployment Snapshot Entries

Use one row per pilot snapshot window (recommended: 24h to 168h windows).

| Snapshot ID | Git Commit | Start (UTC) | End (UTC) | Model Profile | Context Tokens | Concurrency | Sources Completed | Tokens In | Tokens Out | Peak Arrival `lambda_peak_obs` (tok/s) | `mu_compute_obs` (tok/s) | `mu_memory_obs` (tok/s) | `f_fit_obs` | `mu_eff_obs` (tok/s) | `rho_obs` | `r_over_obs` | Peak Memory (GB) | Cloud Spend (USD) | `q_accept_obs` | Notes |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| snap-001 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |

Derived fields for this architecture:

```math
\mu_{eff,obs}=f_{fit,obs}\cdot\min(\mu_{compute,obs},\mu_{memory,obs})
```

```math
\rho_{obs}=\frac{\lambda_{peak,obs}}{\mu_{eff,obs}}, \quad r_{over,obs}=\max\left(0,\frac{\lambda_{peak,obs}-\mu_{eff,obs}}{\lambda_{peak,obs}}\right)
```

```math
C_{month,obs}=S_{obs}\left(0.12\cdot c_h + 0.88\cdot r_{over,obs}\cdot c_e\right)
```

Model versus observed quick check:

| Metric | Model | Observed |
|---|---:|---:|
| `mu_eff` (tok/s) | `180` |  |
| `rho` at baseline | `0.25` |  |
| Cloud cost/month baseline (USD) | `8.14` |  |

## Fit for Project

### Pros

- Strong local throughput for routine indexing and synthesis.
- Low cloud dependence during normal operation.
- Better concurrency margin for team SSH usage.

### Constraints

- Higher upfront capex than `$599` and `$2,500` tiers.
- At `40/month`, capex dominates total cost/source relative to lower tiers.

## Recommended If

Choose this if you want the best balance for a multi-semester research node without stepping into high-end server cost territory.
